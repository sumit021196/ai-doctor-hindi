import streamlit as st
from transformers import pipeline

# Load the model with caching
@st.cache_resource
def load_model():
    return pipeline("text2text-generation", model="google/flan-t5-base")

pipe = load_model()

# Streamlit page setup
st.set_page_config(page_title="AI Doctor - рд╣рд┐рдВрджреА", layout="centered")
st.title("ЁЯй║ AI Doctor (рд╣рд┐рдВрджреА рдореЗрдВ)")
st.markdown("**рдХреГрдкрдпрд╛ рдЕрдкрдиреЗ рд▓рдХреНрд╖рдг рдиреАрдЪреЗ рд╣рд┐рдВрджреА рдореЗрдВ рд▓рд┐рдЦреЗрдВ (рдЬреИрд╕реЗ - рдмреБрдЦрд╛рд░, рдЦрд╛рдВрд╕реА, рдЧрд▓реЗ рдореЗрдВ рджрд░реНрдж)ред**")

# Input box for symptoms
symptoms = st.text_area("рд▓рдХреНрд╖рдг рджрд░реНрдЬ рдХрд░реЗрдВ:", height=150)

# Diagnose button
if st.button("ЁЯза рдирд┐рджрд╛рди рдХрд░реЗрдВ"):
    if not symptoms.strip():
        st.warning("рдХреГрдкрдпрд╛ рдХреБрдЫ рд▓рдХреНрд╖рдг рджрд░реНрдЬ рдХрд░реЗрдВред")
    else:
        prompt = f"""
        рдорд░реАрдЬ рдиреЗ рдмрддрд╛рдпрд╛: {symptoms}
        рдЖрдк рдПрдХ рдЕрдиреБрднрд╡реА рдбреЙрдХреНрдЯрд░ рд╣реИрдВред рдХреГрдкрдпрд╛ рд╕рдВрднрд╛рд╡рд┐рдд рдмреАрдорд╛рд░реА, рдЬрд╝рд░реВрд░реА рдЯреЗрд╕реНрдЯ рдФрд░ рджрд╡рд╛рдЗрдпрд╛рдБ рд╣рд┐рдВрджреА рдореЗрдВ рд╕рд░рд▓ рднрд╛рд╖рд╛ рдореЗрдВ рдмрддрд╛рдПрдВред
        """
        try:
            result = pipe(prompt, max_new_tokens=200)[0]['generated_text']
            st.success("тЬЕ рдирд┐рджрд╛рди рдФрд░ рдкрд░рд╛рдорд░реНрд╢:")
            st.write(result)
        except Exception as e:
            st.error("рдореЙрдбрд▓ рд╕реЗ рдЙрддреНрддрд░ рдкреНрд░рд╛рдкреНрдд рдХрд░рдиреЗ рдореЗрдВ рддреНрд░реБрдЯрд┐ рд╣реБрдИред рдХреГрдкрдпрд╛ рдкреБрдирдГ рдкреНрд░рдпрд╛рд╕ рдХрд░реЗрдВред")
            st.exception(e)
