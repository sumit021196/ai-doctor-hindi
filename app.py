import streamlit as st
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
import torch

# Load model and tokenizer only once
@st.cache_resource
def load_model():
    model_name = "google/flan-t5-base"
    tokenizer = AutoTokenizer.from_pretrained("google/flan-t5-base")
    model = AutoModelForSeq2SeqLM.from_pretrained("google/flan-t5-base")
    return tokenizer, model

tokenizer, model = load_model()

# Streamlit UI
st.set_page_config(page_title="AI Doctor - Hindi", layout="centered")
st.title("ü©∫ AI Doctor (‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç)")

st.markdown("‡§ï‡•É‡§™‡§Ø‡§æ ‡§Ö‡§™‡§®‡•á ‡§≤‡§ï‡•ç‡§∑‡§£ ‡§®‡•Ä‡§ö‡•á ‡§≤‡§ø‡§ñ‡•á‡§Ç (‡§ú‡•à‡§∏‡•á - ‡§¨‡•Å‡§ñ‡§æ‡§∞, ‡§ñ‡§æ‡§Ç‡§∏‡•Ä, ‡§ó‡§≤‡•á ‡§Æ‡•á‡§Ç ‡§¶‡§∞‡•ç‡§¶)‡•§")

# Input Box
symptoms = st.text_area("‡§≤‡§ï‡•ç‡§∑‡§£ ‡§¶‡§∞‡•ç‡§ú ‡§ï‡§∞‡•á‡§Ç:", height=150)

if st.button("üß† ‡§®‡§ø‡§¶‡§æ‡§® ‡§ï‡§∞‡•á‡§Ç (Diagnose)"):
    if symptoms.strip() == "":
        st.warning("‡§ï‡•É‡§™‡§Ø‡§æ ‡§ï‡•Å‡§õ ‡§≤‡§ï‡•ç‡§∑‡§£ ‡§¶‡§∞‡•ç‡§ú ‡§ï‡§∞‡•á‡§Ç‡•§")
    else:
        # Create Prompt
        prompt = f"""
        ‡§Æ‡§∞‡•Ä‡§ú ‡§®‡•á ‡§¨‡§§‡§æ‡§Ø‡§æ: {symptoms}
        ‡§Ü‡§™ ‡§è‡§ï ‡§Ö‡§®‡•Å‡§≠‡§µ‡•Ä ‡§°‡•â‡§ï‡•ç‡§ü‡§∞ ‡§π‡•à‡§Ç‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§∏‡§Ç‡§≠‡§æ‡§µ‡§ø‡§§ ‡§¨‡•Ä‡§Æ‡§æ‡§∞‡•Ä, ‡§ú‡§º‡§∞‡•Ç‡§∞‡•Ä ‡§ü‡•á‡§∏‡•ç‡§ü ‡§î‡§∞ ‡§¶‡§µ‡§æ‡§á‡§Ø‡§æ‡§Å ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§∏‡§∞‡§≤ ‡§≠‡§æ‡§∑‡§æ ‡§Æ‡•á‡§Ç ‡§¨‡§§‡§æ‡§è‡§Ç‡•§
        """

        # Tokenize and generate
        inputs = tokenizer(prompt, return_tensors="pt", truncation=True)
        outputs = model.generate(**inputs, max_new_tokens=200)

        # Decode and show result
        result = tokenizer.decode(outputs[0], skip_special_tokens=True)
        st.success("‚úÖ ‡§®‡§ø‡§¶‡§æ‡§® ‡§î‡§∞ ‡§™‡§∞‡§æ‡§Æ‡§∞‡•ç‡§∂:")
        st.write(result)
